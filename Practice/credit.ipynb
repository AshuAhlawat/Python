{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataset = pd.read_csv(\"./CreditWorthiness.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Cbal         1000 non-null   object\n",
      " 1   Cdur         1000 non-null   int64 \n",
      " 2   Chist        1000 non-null   object\n",
      " 3   Cpur         1000 non-null   object\n",
      " 4   Camt         1000 non-null   int64 \n",
      " 5   Sbal         1000 non-null   object\n",
      " 6   Edur         1000 non-null   object\n",
      " 7   InRate       1000 non-null   int64 \n",
      " 8   MSG          1000 non-null   object\n",
      " 9   Oparties     1000 non-null   object\n",
      " 10  Rdur         1000 non-null   object\n",
      " 11  Prop         1000 non-null   object\n",
      " 12  age          1000 non-null   int64 \n",
      " 13  inPlans      1000 non-null   object\n",
      " 14  Htype        1000 non-null   object\n",
      " 15  NumCred      1000 non-null   int64 \n",
      " 16  JobType      1000 non-null   object\n",
      " 17  Ndepend      1000 non-null   int64 \n",
      " 18  telephone    1000 non-null   object\n",
      " 19  foreign      1000 non-null   object\n",
      " 20  creditScore  1000 non-null   object\n",
      "dtypes: int64(6), object(15)\n",
      "memory usage: 164.2+ KB\n",
      "None\n",
      "              Cdur          Camt       InRate          age      NumCred  \\\n",
      "count  1000.000000    1000.00000  1000.000000  1000.000000  1000.000000   \n",
      "mean     20.903000   32592.58000     2.973000    35.546000     1.407000   \n",
      "std      12.058814   28227.36876     1.118715    11.375469     0.577654   \n",
      "min       4.000000    2380.00000     1.000000    19.000000     1.000000   \n",
      "25%      12.000000   13535.00000     2.000000    27.000000     1.000000   \n",
      "50%      18.000000   23075.00000     3.000000    33.000000     1.000000   \n",
      "75%      24.000000   39602.50000     4.000000    42.000000     2.000000   \n",
      "max      72.000000  184120.00000     4.000000    75.000000     4.000000   \n",
      "\n",
      "           Ndepend  \n",
      "count  1000.000000  \n",
      "mean      1.155000  \n",
      "std       0.362086  \n",
      "min       1.000000  \n",
      "25%       1.000000  \n",
      "50%       1.000000  \n",
      "75%       1.000000  \n",
      "max       2.000000  \n",
      "                       Cbal                 Chist         Cpur        Sbal  \\\n",
      "count                  1000                  1000         1000        1000   \n",
      "unique                    4                     4           10           5   \n",
      "top     no checking account  all settled till now  electronics  Rs. < 1000   \n",
      "freq                    394                   618          280         603   \n",
      "\n",
      "                Edur          MSG Oparties               Rdur  \\\n",
      "count           1000         1000     1000               1000   \n",
      "unique             5            4        3                  4   \n",
      "top     1 to 4 years  single male   no one  more than 3 years   \n",
      "freq             339          548      907                413   \n",
      "\n",
      "                   Prop inPlans Htype                          JobType  \\\n",
      "count              1000    1000  1000                             1000   \n",
      "unique                4       3     3                                4   \n",
      "top     Other cars etc.    none   own  employee with official position   \n",
      "freq                332     814   713                              630   \n",
      "\n",
      "       telephone foreign creditScore  \n",
      "count       1000    1000        1000  \n",
      "unique         2       2           2  \n",
      "top           no      no        good  \n",
      "freq         596     963         700  \n"
     ]
    }
   ],
   "source": [
    "print(dataset.info())\n",
    "print(dataset.describe())\n",
    "print(dataset.describe(include=\"O\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 ['1000 <= Rs. < 5,000' '5000 <= Rs. < 10,000' 'Rs. < 1000' 'Rs. >= 10,000'\n",
      " 'no savings account']\n"
     ]
    }
   ],
   "source": [
    "sbal = np.unique(dataset['Sbal'])\n",
    "\n",
    "print(len(sbal), sbal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.436860068259385\n"
     ]
    }
   ],
   "source": [
    "dues_index = np.where(dataset[\"Chist\"]=='dues not paid earlier')\n",
    "\n",
    "dues_age = []\n",
    "\n",
    "for i in dues_index[0]:\n",
    "    dues_age.append(dataset[\"age\"][i])\n",
    "\n",
    "print(np.array(dues_age).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['creditScore']=dataset['creditScore'].map({'bad':0,'good':1})\n",
    "hot_data = pd.get_dummies(dataset, drop_first=True)\n",
    "\n",
    "outputs = hot_data[\"creditScore_good\"]\n",
    "\n",
    "inputs = hot_data.drop(\"creditScore_good\", axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    9 13790     2 ...     0     1     0]\n",
      " [   15 15250     4 ...     0     1     0]\n",
      " [   36 19410     4 ...     0     1     0]\n",
      " ...\n",
      " [   36 95540     2 ...     0     0     0]\n",
      " [   18 19490     3 ...     0     0     0]\n",
      " [   36 62170     4 ...     1     1     0]]\n",
      "[1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1\n",
      " 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0\n",
      " 1 0 1 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1\n",
      " 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1\n",
      " 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0\n",
      " 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 0\n",
      " 0 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 1 1 0 0 1 1 0\n",
      " 1 1 1 0 1 1 0 0 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 0 0 0 1 0\n",
      " 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 1\n",
      " 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 0 1 0 1\n",
      " 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 0 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 0 0 1 0 0 1\n",
      " 1 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 0 0 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1\n",
      " 0 0 1 0 0 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "print(inputs.values)\n",
    "print(outputs.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748\n"
     ]
    }
   ],
   "source": [
    "train_in,test_in,train_out,test_out = train_test_split(inputs,outputs,test_size=0.25, random_state=1)\n",
    "\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "logistic.fit(train_in,train_out)\n",
    "\n",
    "prediction = logistic.predict(test_in)\n",
    "\n",
    "acc=accuracy_score(test_out, prediction)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.776\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "inputs = scaler.fit_transform(inputs)\n",
    "\n",
    "train_in,test_in,train_out,test_out = train_test_split(inputs,outputs,test_size=0.25, random_state=1)\n",
    "\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "logistic.fit(train_in,train_out)\n",
    "\n",
    "prediction = logistic.predict(test_in)\n",
    "\n",
    "std_acc=accuracy_score(test_out, prediction)\n",
    "print(std_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11111111111111116\n"
     ]
    }
   ],
   "source": [
    "x = (1-std_acc)/(1-acc)\n",
    "print(1-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.788\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=30)\n",
    "classifier.fit(train_in,train_out)\n",
    "prediction = classifier.predict(test_in)\n",
    "acc = accuracy_score(test_out, prediction)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
